{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "14004b96",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "358444bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import SparkSession to create Spark app and access DataFrame APIs\n",
    "\n",
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "34b480ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Spark session with the name 'spark-pract'\n",
    "\n",
    "spark = SparkSession.builder.appName('spark-pract').getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c4ad3bcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_spark = spark.read.csv('food_consumption.csv',header=True,inferSchema=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d3956c98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+--------------------+-----------+-------------+\n",
      "|  country|       food_category|consumption|co2_emmission|\n",
      "+---------+--------------------+-----------+-------------+\n",
      "|Argentina|                Pork|      10.51|         37.2|\n",
      "|Argentina|             Poultry|      38.66|        41.53|\n",
      "|Argentina|                Beef|      55.48|       1712.0|\n",
      "|Argentina|         Lamb & Goat|       1.56|        54.63|\n",
      "|Argentina|                Fish|       4.36|         6.96|\n",
      "|Argentina|                Eggs|      11.39|        10.46|\n",
      "|Argentina|  Milk - inc. cheese|     195.08|       277.87|\n",
      "|Argentina|Wheat and Wheat P...|     103.11|        19.66|\n",
      "|Argentina|                Rice|       8.77|        11.22|\n",
      "|Argentina|            Soybeans|        0.0|          0.0|\n",
      "|Argentina|Nuts inc. Peanut ...|       0.49|         0.87|\n",
      "|Australia|                Pork|      24.14|        85.44|\n",
      "|Australia|             Poultry|      46.12|        49.54|\n",
      "|Australia|                Beef|      33.86|      1044.85|\n",
      "|Australia|         Lamb & Goat|       9.87|       345.65|\n",
      "|Australia|                Fish|      17.69|        28.25|\n",
      "|Australia|                Eggs|       8.51|         7.82|\n",
      "|Australia|  Milk - inc. cheese|     234.49|       334.01|\n",
      "|Australia|Wheat and Wheat P...|      70.46|        13.44|\n",
      "|Australia|                Rice|      11.03|        14.12|\n",
      "+---------+--------------------+-----------+-------------+\n",
      "only showing top 20 rows\n"
     ]
    }
   ],
   "source": [
    "df_spark.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "462bd743",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import StringIndexer, VectorAssembler\n",
    "from pyspark.ml.regression import LinearRegression\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.evaluation import RegressionEvaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "91f83548",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Quality Check: Count null values in each column\n",
    "# This helps identify data completeness issues before modeling\n",
    "# Remove rows where target variable (co2_emmission) or key features are missing\n",
    "# Clean data is essential for reliable model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b2bfdb6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------------+-----------+-------------+\n",
      "|country|food_category|consumption|co2_emmission|\n",
      "+-------+-------------+-----------+-------------+\n",
      "|     10|           10|         10|           10|\n",
      "+-------+-------------+-----------+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col, isnan, when, count\n",
    "\n",
    "df_spark.select([count(when(col(c).isNull(), c)).alias(c) for c in df_spark.columns]).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b91fa79",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_spark = df_spark.dropna(subset=[\"co2_emmission\", \"consumption\"])  # Drop if important columns are null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "6ec9ded2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert categorical variables to numerical indices\n",
    "\n",
    "indexer_country = StringIndexer(inputCol=\"country\", outputCol=\"country_index\")\n",
    "indexer_food = StringIndexer(inputCol=\"food_category\", outputCol=\"food_index\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "46b428ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine all features into a single vector\n",
    "\n",
    "assembler = VectorAssembler(\n",
    "    inputCols=[\"country_index\", \"food_index\", \"consumption\"],\n",
    "    outputCol=\"features\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "16f036e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create linear regression model\n",
    "lr = LinearRegression(featuresCol=\"features\", labelCol=\"co2_emmission\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "8d469440",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build ML pipeline with all preprocessing and modeling steps\n",
    "pipeline = Pipeline(stages=[indexer_country, indexer_food, assembler, lr])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "7d16f22e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into training (80%) and testing (20%) sets\n",
    "train_data, test_data = df_spark.randomSplit([0.8, 0.2], seed=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "5d062988",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the complete pipeline\n",
    "model = pipeline.fit(train_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "4bbd987f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+-------------------+\n",
      "|co2_emmission|         prediction|\n",
      "+-------------+-------------------+\n",
      "|         6.15|-21.333345844735447|\n",
      "|        38.51|-1.4304751446120463|\n",
      "|         9.96|   42.0567986837257|\n",
      "|         5.97|-17.398738617472645|\n",
      "|          3.8|   42.8396783426316|\n",
      "|         1.02|  71.85188756389933|\n",
      "|        18.62|  37.16262771361305|\n",
      "|         6.96|-12.385141413677445|\n",
      "|        10.74|   70.8119920998454|\n",
      "|         6.96|-25.235507471695684|\n",
      "+-------------+-------------------+\n",
      "only showing top 10 rows\n"
     ]
    }
   ],
   "source": [
    "# Make predictions on test data\n",
    "predictions = model.transform(test_data)\n",
    "predictions.select(\"co2_emmission\", \"prediction\").show(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "e549ece6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 115.20849139249091\n"
     ]
    }
   ],
   "source": [
    "# Evaluate model performance using multiple metrics\n",
    "evaluator = RegressionEvaluator(\n",
    "    labelCol=\"co2_emmission\", predictionCol=\"prediction\", metricName=\"rmse\")\n",
    "\n",
    "rmse = evaluator.evaluate(predictions)\n",
    "print(f\"RMSE: {rmse}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "b045afb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2: 0.15491332585713546, MAE: 63.228830160901886\n"
     ]
    }
   ],
   "source": [
    "# Additional metrics for comprehensive evaluation\n",
    "\n",
    "r2 = evaluator.setMetricName(\"r2\").evaluate(predictions)\n",
    "mae = evaluator.setMetricName(\"mae\").evaluate(predictions)\n",
    "\n",
    "print(f\"R2: {r2}, MAE: {mae}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81136db6",
   "metadata": {},
   "source": [
    "As can be seen the label encoding , liner regression approach doesnt result into decent scores , as the models fails to learn on 15 % of variance.\n",
    "\n",
    "We now shift to some advanced ML models , Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "42a44af0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_spark = spark.read.csv('food_consumption.csv',header=True,inferSchema=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "8729cd96",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import log1p\n",
    "from pyspark.ml.feature import StringIndexer, OneHotEncoder, VectorAssembler\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.regression import RandomForestRegressor\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "676ccfb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Log transform target and numeric feature\n",
    "df_spark = df_spark.withColumn(\"log_co2\", log1p(\"co2_emmission\")) \\\n",
    "                   .withColumn(\"log_consumption\", log1p(\"consumption\"))\n",
    "\n",
    "# 2. Drop rows with nulls in important columns\n",
    "df_spark = df_spark.dropna(subset=[\"country\", \"food_category\", \"consumption\", \"co2_emmission\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "22517664",
   "metadata": {},
   "outputs": [],
   "source": [
    "# String Indexing\n",
    "indexer_country = StringIndexer(inputCol=\"country\", outputCol=\"country_index\")\n",
    "indexer_food = StringIndexer(inputCol=\"food_category\", outputCol=\"food_index\")\n",
    "\n",
    "# One-Hot Encoding\n",
    "encoder_country = OneHotEncoder(inputCol=\"country_index\", outputCol=\"country_ohe\")\n",
    "encoder_food = OneHotEncoder(inputCol=\"food_index\", outputCol=\"food_ohe\")\n",
    "\n",
    "# Assemble features\n",
    "assembler = VectorAssembler(\n",
    "    inputCols=[\"country_ohe\", \"food_ohe\", \"log_consumption\"],\n",
    "    outputCol=\"features\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "ac46e9dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestRegressor(featuresCol=\"features\", labelCol=\"log_co2\", numTrees=100, maxDepth=6)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "eeb36fb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline(stages=[\n",
    "    indexer_country,\n",
    "    indexer_food,\n",
    "    encoder_country,\n",
    "    encoder_food,\n",
    "    assembler,\n",
    "    rf\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "93eb4cb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+--------------------+-----------+-------------+------------------+------------------+\n",
      "|  country|       food_category|consumption|co2_emmission|           log_co2|   log_consumption|\n",
      "+---------+--------------------+-----------+-------------+------------------+------------------+\n",
      "|Argentina|                Pork|      10.51|         37.2|3.6428355156125294| 2.443216222733791|\n",
      "|Argentina|             Poultry|      38.66|        41.53| 3.750209709265542|  3.68034312309165|\n",
      "|Argentina|                Beef|      55.48|       1712.0|  7.44600149832412| 4.033886593184986|\n",
      "|Argentina|         Lamb & Goat|       1.56|        54.63| 4.018722624087202|0.9400072584914712|\n",
      "|Argentina|                Fish|       4.36|         6.96|2.0744289998562917|1.6789639750827106|\n",
      "|Argentina|                Eggs|      11.39|        10.46|2.4388627112865935|2.5168896956410514|\n",
      "|Argentina|  Milk - inc. cheese|     195.08|       277.87| 5.630745723412227|5.2785227392198575|\n",
      "|Argentina|Wheat and Wheat P...|     103.11|        19.66|3.0281994636914926| 4.645448032486661|\n",
      "|Argentina|                Rice|       8.77|        11.22| 2.503073953743449|2.2793164660546914|\n",
      "|Argentina|            Soybeans|        0.0|          0.0|               0.0|               0.0|\n",
      "|Argentina|Nuts inc. Peanut ...|       0.49|         0.87|0.6259384308664953|0.3987761199573678|\n",
      "|Australia|                Pork|      24.14|        85.44| 4.459450531638685|3.2244602031621015|\n",
      "|Australia|             Poultry|      46.12|        49.54| 3.922765101960048|3.8526975393433314|\n",
      "|Australia|                Beef|      33.86|      1044.85|6.9525852308999285| 3.551340040091875|\n",
      "|Australia|         Lamb & Goat|       9.87|       345.65|   5.8483156253885| 2.386006701133118|\n",
      "|Australia|                Fish|      17.69|        28.25|3.3758795736778655|2.9279886214674717|\n",
      "|Australia|                Eggs|       8.51|         7.82|   2.1770218700187| 2.252343876557299|\n",
      "|Australia|  Milk - inc. cheese|     234.49|       334.01|  5.81416038212581|  5.46166844970989|\n",
      "|Australia|Wheat and Wheat P...|      70.46|        13.44|  2.67000213346468|4.2691378525952635|\n",
      "|Australia|                Rice|      11.03|        14.12| 2.716018370751387|2.4874035299865875|\n",
      "+---------+--------------------+-----------+-------------+------------------+------------------+\n",
      "only showing top 20 rows\n"
     ]
    }
   ],
   "source": [
    "df_spark.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "d32098d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, test_data = df_spark.randomSplit([0.8, 0.2], seed=42)\n",
    "model = pipeline.fit(train_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "873472e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+------------------+\n",
      "|co2_emmission|        prediction|\n",
      "+-------------+------------------+\n",
      "|         6.15|   2.3142473693444|\n",
      "|        38.51|3.0568055867921315|\n",
      "|         9.96| 2.647743908744865|\n",
      "|         5.97|   2.3142473693444|\n",
      "|          3.8|1.8846909515698747|\n",
      "|         1.02|1.4492803731429416|\n",
      "|        18.62|3.2977640185222974|\n",
      "|         6.96|2.5429763385996362|\n",
      "|        10.74|2.4305441509369943|\n",
      "|         6.96|2.5429763385996362|\n",
      "+-------------+------------------+\n",
      "only showing top 10 rows\n"
     ]
    }
   ],
   "source": [
    "predictions = model.transform(test_data)\n",
    "predictions.select(\"co2_emmission\", \"prediction\").show(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "08bc21ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“‰ RMSE: 80.10442487706983\n",
      "ðŸ“ˆ R2: 0.5914499317573629\n",
      "ðŸ“‰ MAE: 26.199434662519803\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import expm1\n",
    "\n",
    "# Inverse log for actual and predicted\n",
    "predictions = predictions.withColumn(\"prediction_exp\", expm1(\"prediction\"))\n",
    "evaluator = RegressionEvaluator(labelCol=\"co2_emmission\", predictionCol=\"prediction_exp\")\n",
    "\n",
    "print(\"ðŸ“‰ RMSE:\", evaluator.setMetricName(\"rmse\").evaluate(predictions))\n",
    "print(\"ðŸ“ˆ R2:\", evaluator.setMetricName(\"r2\").evaluate(predictions))\n",
    "print(\"ðŸ“‰ MAE:\", evaluator.setMetricName(\"mae\").evaluate(predictions))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96dfb0c6",
   "metadata": {},
   "source": [
    "Using the Random Forest Regressor , the variance capturing ability of the model increase by 4 times , and scaling the numerical features by log also added to the model capability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "16556e6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.tuning import ParamGridBuilder, CrossValidator\n",
    "\n",
    "# Step 10: Hyperparameter Tuning\n",
    "paramGrid = ParamGridBuilder() \\\n",
    "    .addGrid(rf.numTrees, [50, 100]) \\\n",
    "    .addGrid(rf.maxDepth, [4, 6, 8]) \\\n",
    "    .addGrid(rf.minInstancesPerNode, [1, 2]) \\\n",
    "    .build()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "657f6040",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator = RegressionEvaluator(labelCol=\"log_co2\", predictionCol=\"prediction\", metricName=\"r2\")\n",
    "\n",
    "cv = CrossValidator(estimator=pipeline,\n",
    "                    estimatorParamMaps=paramGrid,\n",
    "                    evaluator=evaluator,\n",
    "                    numFolds=3,\n",
    "                    parallelism=2,\n",
    "                    seed=42)\n",
    "\n",
    "# Step 11: Fit CrossValidator\n",
    "cv_model = cv.fit(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "310ba61d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Best Model Params:\n",
      "- Num Trees: 50\n",
      "- Max Depth: 8\n"
     ]
    }
   ],
   "source": [
    "# Step 12: Get Best Model from CrossValidator\n",
    "best_model = cv_model.bestModel\n",
    "\n",
    "print(\"âœ… Best Model Params:\")\n",
    "print(f\"- Num Trees: {best_model.stages[-1]._java_obj.getNumTrees()}\")\n",
    "print(f\"- Max Depth: {best_model.stages[-1]._java_obj.getMaxDepth()}\")\n",
    "\n",
    "# Step 13: Retrain Best Model (Optional, skipped here since it's already trained on full training set)\n",
    "\n",
    "# Step 14: Predict on Test Set\n",
    "predictions = best_model.transform(test_data)\n",
    "\n",
    "# Step 15: Evaluate (Inverse log to get back real CO2 emission values)\n",
    "predictions = predictions.withColumn(\"prediction_exp\", expm1(\"prediction\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "2cab5c35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ“Š Final Evaluation on Test Set:\n",
      "- RMSE: 80.1044\n",
      "- RÂ²: 0.5914\n",
      "- MAE: 26.1994\n"
     ]
    }
   ],
   "source": [
    "# Metrics on real scale\n",
    "evaluator_real = RegressionEvaluator(labelCol=\"co2_emmission\", predictionCol=\"prediction_exp\")\n",
    "\n",
    "rmse = evaluator_real.setMetricName(\"rmse\").evaluate(predictions)\n",
    "r2 = evaluator_real.setMetricName(\"r2\").evaluate(predictions)\n",
    "mae = evaluator_real.setMetricName(\"mae\").evaluate(predictions)\n",
    "\n",
    "print(f\"\\nðŸ“Š Final Evaluation on Test Set:\")\n",
    "print(f\"- RMSE: {rmse:.4f}\")\n",
    "print(f\"- RÂ²: {r2:.4f}\")\n",
    "print(f\"- MAE: {mae:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2de0d8d3",
   "metadata": {},
   "source": [
    "Upon Hyper Parameter tuning , The model has improved to 80% variance capture which makes the model more able with right set of parameters for the model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95c59ef4",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
